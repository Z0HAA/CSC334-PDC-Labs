{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AZtwk01v2QQn",
        "outputId": "7c1436a0-a234-4b75-973c-8f64afc20831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libslurm37.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../libslurm37_21.08.5-2ubuntu1_amd64.deb ...\n",
            "Unpacking libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Selecting previously unselected package hwloc-nox.\n",
            "Preparing to unpack .../hwloc-nox_2.7.0-2ubuntu1_amd64.deb ...\n",
            "Unpacking hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Selecting previously unselected package libmpich12:amd64.\n",
            "Preparing to unpack .../libmpich12_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich12:amd64 (4.0-3) ...\n",
            "Selecting previously unselected package mpich.\n",
            "Preparing to unpack .../archives/mpich_4.0-3_amd64.deb ...\n",
            "Unpacking mpich (4.0-3) ...\n",
            "Selecting previously unselected package libmpich-dev:amd64.\n",
            "Preparing to unpack .../libmpich-dev_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich-dev:amd64 (4.0-3) ...\n",
            "Setting up libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Setting up hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Setting up libmpich12:amd64 (4.0-3) ...\n",
            "Setting up mpich (4.0-3) ...\n",
            "Setting up libmpich-dev:amd64 (4.0-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
            "Downloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.1.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install mpich\n",
        "!pip install mpi4py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_vector_sum_bonus.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <mpi.h>\n",
        "\n",
        "// Task: Distributed Partial Summation + Average using MPI_Allreduce\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "    int rank, size;\n",
        "    long N = 10000000;               // Vector size\n",
        "    double *A = NULL;                // Full vector (root only)\n",
        "    double *local_A = NULL;          // Local part for each process\n",
        "    double local_sum = 0.0, global_sum = 0.0;\n",
        "    double start_time, end_time, parallel_time, serial_time;\n",
        "\n",
        "    //  Initialize MPI environment\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    // Task 1: Vector Initialization (root only)\n",
        "    long base = N / size;\n",
        "    long remainder = N % size;\n",
        "    long local_n = base + (rank < remainder ? 1 : 0);\n",
        "\n",
        "    int *counts = (int*)malloc(size * sizeof(int));\n",
        "    int *displs = (int*)malloc(size * sizeof(int));\n",
        "\n",
        "    displs[0] = 0;\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        counts[i] = (int)(base + (i < remainder ? 1 : 0));\n",
        "        if (i > 0) displs[i] = displs[i - 1] + counts[i - 1];\n",
        "    }\n",
        "\n",
        "    if (rank == 0) {\n",
        "        A = (double*)malloc(N * sizeof(double));\n",
        "        for (long i = 0; i < N; i++)\n",
        "            A[i] = i + 1; // A[i] = i + 1\n",
        "    }\n",
        "\n",
        "    local_A = (double*)malloc(local_n * sizeof(double));\n",
        "\n",
        "    //  Task 2: Data Distribution (uneven partitions using MPI_Scatterv)\n",
        "    MPI_Scatterv(A, counts, displs, MPI_DOUBLE, local_A, local_n, MPI_DOUBLE, 0, MPI_COMM_WORLD);\n",
        "\n",
        "    //  Task 3: Local Computation (partial sum)\n",
        "    start_time = MPI_Wtime();\n",
        "    for (long i = 0; i < local_n; i++)\n",
        "        local_sum += local_A[i];\n",
        "\n",
        "    //  Task 4: Reduction + Average using MPI_Allreduce\n",
        "    MPI_Allreduce(&local_sum, &global_sum, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);\n",
        "    double global_avg = global_sum / N;\n",
        "    end_time = MPI_Wtime();\n",
        "    parallel_time = end_time - start_time;\n",
        "\n",
        "    // Task 5: Serial Computation\n",
        "    if (rank == 0) {\n",
        "        double serial_sum = 0.0;\n",
        "        double serial_start = MPI_Wtime();\n",
        "        for (long i = 0; i < N; i++)\n",
        "            serial_sum += A[i];\n",
        "        double serial_end = MPI_Wtime();\n",
        "        serial_time = serial_end - serial_start;\n",
        "\n",
        "        //  Display Results\n",
        "        double expected = (N * (N + 1)) / 2.0;\n",
        "        printf(\"\\n=== MPI Parallel Vector Sum + Average ===\\n\");\n",
        "        printf(\"Processes        : %d\\n\", size);\n",
        "        printf(\"Total Elements   : %ld\\n\", N);\n",
        "        printf(\"Computed Sum     : %.0f\\n\", global_sum);\n",
        "        printf(\"Expected Sum     : %.0f\\n\", expected);\n",
        "        printf(\"Difference       : %.5f\\n\", expected - global_sum);\n",
        "        printf(\"Computed Average : %.5f\\n\", global_avg);\n",
        "        printf(\"Parallel Time    : %.6f sec\\n\", parallel_time);\n",
        "        printf(\"Serial Time      : %.6f sec\\n\", serial_time);\n",
        "        printf(\"Speedup          : %.2fx\\n\", serial_time / parallel_time);\n",
        "    }\n",
        "\n",
        "    //  Cleanup\n",
        "    free(local_A);\n",
        "    free(counts);\n",
        "    free(displs);\n",
        "    if (rank == 0) free(A);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8X-ljwqfyJ4",
        "outputId": "85eada72-3298-4299-813c-75ede4e2a084"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_vector_sum_bonus.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc mpi_vector_sum_bonus.c -o mpi_vector_sum_bonus\n"
      ],
      "metadata": {
        "id": "x_FSLwIdf8o4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_vector_sum_bonus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k3czlVFf9-C",
        "outputId": "41580c27-69d4-4c17-858d-8eee65116962"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MPI Parallel Vector Sum + Average ===\n",
            "Processes        : 4\n",
            "Total Elements   : 10000000\n",
            "Computed Sum     : 50000005000000\n",
            "Expected Sum     : 50000005000000\n",
            "Difference       : 0.00000\n",
            "Computed Average : 5000000.50000\n",
            "Parallel Time    : 0.011379 sec\n",
            "Serial Time      : 0.035920 sec\n",
            "Speedup          : 3.16x\n"
          ]
        }
      ]
    }
  ]
}