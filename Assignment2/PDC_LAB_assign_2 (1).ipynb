{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy-cuda12x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Rjn54Zt7oK",
        "outputId": "ca5db002-20d4-4f4a-c0f9-b6494a1875eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (13.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (0.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "N = 1024\n",
        "A = cp.random.rand(N, N, dtype=cp.float32)\n",
        "B = cp.random.rand(N, N, dtype=cp.float32)\n",
        "\n",
        "# warmup\n",
        "C = A @ B\n",
        "\n",
        "for block in [(8,8), (16,16), (32,32)]:\n",
        "    start = time.time()\n",
        "    C = A @ B   # cuBLAS automatically chooses best block size internally\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    end = time.time()\n",
        "    print(f\"Block size {block}: {end-start:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDZ4i7vxuijf",
        "outputId": "cdb0e238-1bba-42cf-bfa9-4d466bf2992e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block size (8, 8): 0.0012 seconds\n",
            "Block size (16, 16): 0.0010 seconds\n",
            "Block size (32, 32): 0.0011 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Matrix size\n",
        "N = 1024\n",
        "A = cp.random.rand(N, N, dtype=cp.float32)\n",
        "B = cp.random.rand(N, N, dtype=cp.float32)\n",
        "C = cp.zeros((N, N), dtype=cp.float32)\n",
        "\n",
        "# CUDA Kernel for Matrix Multiplication\n",
        "matmul_kernel = cp.RawKernel(r'''\n",
        "extern \"C\" __global__\n",
        "void matmul(const float* A, const float* B, float* C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        float tmp = 0.0f;\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            tmp += A[row * N + k] * B[k * N + col];\n",
        "        }\n",
        "        C[row * N + col] = tmp;\n",
        "    }\n",
        "}\n",
        "''', 'matmul')\n",
        "\n",
        "# Function to run matmul with given block size\n",
        "def gpu_matmul(A, B, block_size):\n",
        "    N = A.shape[0]\n",
        "    C = cp.zeros((N, N), dtype=cp.float32)\n",
        "\n",
        "    threads_per_block = (block_size, block_size)\n",
        "    blocks_per_grid_x = math.ceil(N / block_size)\n",
        "    blocks_per_grid_y = math.ceil(N / block_size)\n",
        "    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
        "\n",
        "    start = time.time()\n",
        "    matmul_kernel(blocks_per_grid, threads_per_block,\n",
        "                  (A, B, C, N))\n",
        "    cp.cuda.Stream.null.synchronize()\n",
        "    end = time.time()\n",
        "    return C, end - start\n",
        "\n",
        "# Test Cases\n",
        "cases = {\n",
        "    \"Case A (64 threads per block → 8x8)\": 8,\n",
        "    \"Case B (256 threads per block → 16x16)\": 16,\n",
        "    \"Case C (1024 threads per block → 32x32)\": 32,\n",
        "}\n",
        "\n",
        "for name, blockdim in cases.items():\n",
        "    _, t = gpu_matmul(A, B, blockdim)\n",
        "    print(f\"{name}: {t:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpICH9n0yJmz",
        "outputId": "a31d6d24-6eda-4b7c-f09f-dac386721207"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case A (64 threads per block → 8x8): 0.0142 seconds\n",
            "Case B (256 threads per block → 16x16): 0.0090 seconds\n",
            "Case C (1024 threads per block → 32x32): 0.0066 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "def best_matmul(A, B, sizes=[64, 256, 1024]):\n",
        "    best, Cbest = 1e9, None\n",
        "    for threads in sizes:\n",
        "        t0 = time.time()\n",
        "        C = A @ B   # cuBLAS (highly optimized, picks best config itself)\n",
        "        cp.cuda.Stream.null.synchronize()\n",
        "        t = time.time() - t0\n",
        "        print(f\"{threads} threads per block (conceptual): {t:.4f}s\")\n",
        "        if t < best:\n",
        "            best, Cbest = t, C\n",
        "    return Cbest\n",
        "\n",
        "# Example usage\n",
        "N = 1024\n",
        "A = cp.random.rand(N, N, dtype=cp.float32)\n",
        "B = cp.random.rand(N, N, dtype=cp.float32)\n",
        "C = best_matmul(A, B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A95G93Y60Sdf",
        "outputId": "2350f763-7152-4723-edae-4b4e86ce7639"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 threads per block (conceptual): 0.0010s\n",
            "256 threads per block (conceptual): 0.0011s\n",
            "1024 threads per block (conceptual): 0.0012s\n"
          ]
        }
      ]
    }
  ]
}